{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596b43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from gensim import models\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Reshape, Flatten, concatenate, Input, Conv1D, GlobalMaxPooling1D, Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a8c6a1",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a21c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('C:/Users/Admin/OneDrive/Desktop/INS3008-Projects/Comment-shopee.xlsx', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70b783fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['Text','Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f2fde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chất liệu: okii\\nzừi zừi đẹp không có chỗ chê ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chất liệu: okii\\nzừi zừi đẹp không có chỗ chê ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chất liệu: nhung tăm\\nMàu sắc: be với đen\\nĐún...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chất liệu: nhung tăm\\nMàu sắc: be với đen\\nĐún...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chất liệu: Ok\\nMàu sắc: đen\\nĐúng với mô tả: b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  Chất liệu: okii\\nzừi zừi đẹp không có chỗ chê ...      0\n",
       "1  Chất liệu: okii\\nzừi zừi đẹp không có chỗ chê ...      0\n",
       "2  Chất liệu: nhung tăm\\nMàu sắc: be với đen\\nĐún...      0\n",
       "3  Chất liệu: nhung tăm\\nMàu sắc: be với đen\\nĐún...      0\n",
       "4  Chất liệu: Ok\\nMàu sắc: đen\\nĐúng với mô tả: b...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "291d2018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3363"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ce69feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f43cfb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3363, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "165d66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "neg = []\n",
    "neu = []\n",
    "#Pos: 0, Neg:2, Neu:1\n",
    "#False: 0, True:1\n",
    "for l in data.Label:\n",
    "    if l == 0:\n",
    "        pos.append(1)\n",
    "        neg.append(0)\n",
    "        neu.append(0)\n",
    "    elif l == 1:\n",
    "        pos.append(0)\n",
    "        neg.append(0)\n",
    "        neu.append(1)\n",
    "    else:\n",
    "        pos.append(0)\n",
    "        neg.append(1)\n",
    "        neu.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73fae3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Pos']= pos\n",
    "data['Neg']= neg\n",
    "data['Neu']= neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76befaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chất liệu: okii\\nzừi zừi đẹp không có chỗ chê ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chất liệu: okii\\nzừi zừi đẹp không có chỗ chê ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chất liệu: nhung tăm\\nMàu sắc: be với đen\\nĐún...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chất liệu: nhung tăm\\nMàu sắc: be với đen\\nĐún...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chất liệu: Ok\\nMàu sắc: đen\\nĐúng với mô tả: b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  Pos  Neg  Neu\n",
       "0  Chất liệu: okii\\nzừi zừi đẹp không có chỗ chê ...      0    1    0    0\n",
       "1  Chất liệu: okii\\nzừi zừi đẹp không có chỗ chê ...      0    1    0    0\n",
       "2  Chất liệu: nhung tăm\\nMàu sắc: be với đen\\nĐún...      0    1    0    0\n",
       "3  Chất liệu: nhung tăm\\nMàu sắc: be với đen\\nĐún...      0    1    0    0\n",
       "4  Chất liệu: Ok\\nMàu sắc: đen\\nĐúng với mô tả: b...      0    1    0    0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc2e321",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4ca4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = ''\n",
    "    text_nopunct = re.sub('['+string.punctuation+']', '', str(text))\n",
    "    return text_nopunct\n",
    "\n",
    "data['Text_Clean'] = data['Text'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "396b885c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdda1904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "tokens = [word_tokenize(sen) for sen in data.Text_Clean] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10d01027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_token(tokens): \n",
    "    return [w.lower() for w in tokens]    \n",
    "    \n",
    "lower_tokens = [lower_token(token) for token in tokens] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dea457e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27dc1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7960d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tokens): \n",
    "    return [word for word in tokens if word not in stoplist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02b8cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [remove_stop_words(sen) for sen in lower_tokens] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db9523f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [' '.join(sen) for sen in filtered_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec0665d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text_Final'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d6974a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff5862e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Text_Final', 'tokens', 'Label', 'Pos', 'Neg','Neu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4617441e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Final</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Label</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chất liệu okii zừi zừi đẹp không có chỗ chê lu...</td>\n",
       "      <td>[chất, liệu, okii, zừi, zừi, đẹp, không, có, c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chất liệu okii zừi zừi đẹp không có chỗ chê lu...</td>\n",
       "      <td>[chất, liệu, okii, zừi, zừi, đẹp, không, có, c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chất liệu nhung tăm màu sắc với đen đúng với m...</td>\n",
       "      <td>[chất, liệu, nhung, tăm, màu, sắc, với, đen, đ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chất liệu nhung tăm màu sắc với đen đúng với m...</td>\n",
       "      <td>[chất, liệu, nhung, tăm, màu, sắc, với, đen, đ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chất liệu ok màu sắc đen đúng với mô tả bình t...</td>\n",
       "      <td>[chất, liệu, ok, màu, sắc, đen, đúng, với, mô,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text_Final  \\\n",
       "0  chất liệu okii zừi zừi đẹp không có chỗ chê lu...   \n",
       "1  chất liệu okii zừi zừi đẹp không có chỗ chê lu...   \n",
       "2  chất liệu nhung tăm màu sắc với đen đúng với m...   \n",
       "3  chất liệu nhung tăm màu sắc với đen đúng với m...   \n",
       "4  chất liệu ok màu sắc đen đúng với mô tả bình t...   \n",
       "\n",
       "                                              tokens  Label  Pos  Neg  Neu  \n",
       "0  [chất, liệu, okii, zừi, zừi, đẹp, không, có, c...      0    1    0    0  \n",
       "1  [chất, liệu, okii, zừi, zừi, đẹp, không, có, c...      0    1    0    0  \n",
       "2  [chất, liệu, nhung, tăm, màu, sắc, với, đen, đ...      0    1    0    0  \n",
       "3  [chất, liệu, nhung, tăm, màu, sắc, với, đen, đ...      0    1    0    0  \n",
       "4  [chất, liệu, ok, màu, sắc, đen, đúng, với, mô,...      0    1    0    0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54553484",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5769435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "281a4bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112326 words total, with a vocabulary size of 7385\n",
      "Max sentence length is 175\n"
     ]
    }
   ],
   "source": [
    "all_training_words = [word for tokens in data_train[\"tokens\"] for word in tokens]\n",
    "training_sentence_lengths = [len(tokens) for tokens in data_train[\"tokens\"]]\n",
    "TRAINING_VOCAB = sorted(list(set(all_training_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_training_words), len(TRAINING_VOCAB)))\n",
    "print(\"Max sentence length is %s\" % max(training_sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "115c8fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12194 words total, with a vocabulary size of 1893\n",
      "Max sentence length is 141\n"
     ]
    }
   ],
   "source": [
    "all_test_words = [word for tokens in data_test[\"tokens\"] for word in tokens]\n",
    "test_sentence_lengths = [len(tokens) for tokens in data_test[\"tokens\"]]\n",
    "TEST_VOCAB = sorted(list(set(all_test_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_test_words), len(TEST_VOCAB)))\n",
    "print(\"Max sentence length is %s\" % max(test_sentence_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a68d7",
   "metadata": {},
   "source": [
    "## Load Google News Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58ceaa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_path = 'C:/Users/Admin/OneDrive/Desktop/INS3008-Projects/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf4d2ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=300):\n",
    "    if len(tokens_list)<1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
    "    else:\n",
    "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "def get_word2vec_embeddings(vectors, clean_comments, generate_missing=False):\n",
    "    embeddings = clean_comments['tokens'].apply(lambda x: get_average_word2vec(x, vectors, \n",
    "                                                                                generate_missing=generate_missing))\n",
    "    return list(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77757133",
   "metadata": {},
   "source": [
    "## Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ede30b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_embeddings = get_word2vec_embeddings(word2vec, data_train, generate_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c24a9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 50\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8198339",
   "metadata": {},
   "source": [
    "## Tokenize and Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8a1881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7385 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=len(TRAINING_VOCAB), lower=True, char_level=False)\n",
    "tokenizer.fit_on_texts(data_train[\"Text_Final\"].tolist())\n",
    "training_sequences = tokenizer.texts_to_sequences(data_train[\"Text_Final\"].tolist())\n",
    "\n",
    "train_word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(train_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a248f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnn_data = pad_sequences(training_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73948536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7386, 300)\n"
     ]
    }
   ],
   "source": [
    "train_embedding_weights = np.zeros((len(train_word_index)+1, EMBEDDING_DIM))\n",
    "for word,index in train_word_index.items():\n",
    "    train_embedding_weights[index,:] = word2vec[word] if word in word2vec else np.random.rand(EMBEDDING_DIM)\n",
    "print(train_embedding_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "885f31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(data_test[\"Text_Final\"].tolist())\n",
    "test_cnn_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f9565",
   "metadata": {},
   "source": [
    "# Define CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e3af7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvNet(embeddings, max_sequence_length, num_words, embedding_dim, labels_index):\n",
    "    \n",
    "    embedding_layer = Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            weights=[embeddings],\n",
    "                            input_length=max_sequence_length,\n",
    "                            trainable=False)\n",
    "    \n",
    "    sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    convs = []\n",
    "    filter_sizes = [2,3,4,5,6]\n",
    "\n",
    "    for filter_size in filter_sizes:\n",
    "        l_conv = Conv1D(filters=200, kernel_size=filter_size, activation='relu')(embedded_sequences)\n",
    "        l_pool = GlobalMaxPooling1D()(l_conv)\n",
    "        convs.append(l_pool)\n",
    "\n",
    "\n",
    "    l_merge = concatenate(convs, axis=1)\n",
    "\n",
    "    x = Dropout(0.1)(l_merge)  \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    preds = Dense(labels_index, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2922de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['Pos', 'Neg','Neu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a17a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train[label_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3429f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = data_test[label_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc8fc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_cnn_data\n",
    "y_tr = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9590ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_cnn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d7e49a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 300)      2215800     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 49, 200)      120200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 48, 200)      180200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 47, 200)      240200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 46, 200)      300200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 45, 200)      360200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 200)          0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 200)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 200)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 200)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 200)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1000)         0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1000)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          128128      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            387         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,545,315\n",
      "Trainable params: 1,329,515\n",
      "Non-trainable params: 2,215,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(train_embedding_weights, MAX_SEQUENCE_LENGTH, len(train_word_index)+1, EMBEDDING_DIM, \n",
    "                len(list(label_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6a69f",
   "metadata": {},
   "source": [
    "# Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8837606",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "batch_size = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ffddcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "81/81 [==============================] - 13s 108ms/step - loss: 0.2692 - acc: 0.9049 - val_loss: 0.1516 - val_acc: 0.9274\n",
      "Epoch 2/3\n",
      "81/81 [==============================] - 9s 105ms/step - loss: 0.1704 - acc: 0.9144 - val_loss: 0.1207 - val_acc: 0.9274\n",
      "Epoch 3/3\n",
      "81/81 [==============================] - 9s 105ms/step - loss: 0.1406 - acc: 0.9144 - val_loss: 0.1145 - val_acc: 0.9274\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_tr, epochs=num_epochs, validation_split=0.1, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58554d77",
   "metadata": {},
   "source": [
    "# Test CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a91760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 331ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_cnn_data, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cca09a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 89.317507\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6bdf935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99802470e-01, 6.66129881e-06, 7.44650752e-05],\n",
       "       [8.75429511e-01, 1.97670162e-02, 4.44633067e-02],\n",
       "       [9.99549389e-01, 1.64196044e-05, 2.11119652e-04],\n",
       "       ...,\n",
       "       [9.33412790e-01, 9.58180428e-03, 1.86868310e-02],\n",
       "       [9.97795105e-01, 1.37835741e-04, 5.60373068e-04],\n",
       "       [6.64095402e-01, 1.02987856e-01, 1.50198162e-01]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0cb117cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1, 0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d6b3c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels=[]\n",
    "for p in predictions:\n",
    "    prediction_labels.append(labels[np.argmax(p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0889355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08902077151335312"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data_test.Label==prediction_labels)/len(prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a02daf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    301\n",
       "1     30\n",
       "2      6\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a07d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
